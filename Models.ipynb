{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed479922",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf4485",
   "metadata": {},
   "source": [
    "- $\\gamma$ 確認(v)\n",
    "- 資料集跟 paper 少部份不一樣(v)\n",
    "- P1 解不出來..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329dad87",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811111e",
   "metadata": {},
   "source": [
    "- Check outlier(min, max)\n",
    "- objective + soft margin(slack)\n",
    "- non-linear kernel -> Gaussian kernel(range of $\\gamma$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a1d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e9697",
   "metadata": {},
   "source": [
    "### Data helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56c2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums_of_row:76\n",
      "nums_of_feature:698\n",
      "positive_count:[40]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "class DataHolder():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.files_id = {\n",
    "            \"careval\": 19,\n",
    "            \"wisconsin\": 17,\n",
    "            \"votes\": 105,\n",
    "        }\n",
    "\n",
    "    def get(self, name):\n",
    "\n",
    "        if name == \"nursery\":\n",
    "            df = self.fetch_dataset(name)\n",
    "#             df = df.sample(frac=1)\n",
    "            X = df.loc[:, df.columns[:-1]]\n",
    "            X = self.encode(X)\n",
    "            y = df[df.columns[-1]].to_frame('class')\n",
    "            y = self.multiclass_preprocessing(y)\n",
    "\n",
    "        elif name == \"australian\":\n",
    "            df = self.fetch_dataset(name)\n",
    "            X = df.loc[:, df.columns[:-1]]\n",
    "            X['A1'] = X['A1'].replace({0: 'a', 1: 'b'})\n",
    "            X['A4'] = X['A4'].replace({1: 'p', 2: 'g', 3: 'gg'})\n",
    "            X['A5'] = X['A5'].replace({1: 'ff', 2: 'd', 3: 'i', 4: 'k', 5: 'j', 6: 'aa', 7: 'm', 8: 'c', \n",
    "                                        9: 'w', 10: 'e', 11: 'q', 12: 'r', 13: 'cc', 14: 'x'})\n",
    "            X['A6'] = X['A6'].replace({1: 'ff', 2: 'dd', 3: 'j', 4: 'bb', 5: 'v', 6: 'n', 7: 'o', 8: 'h',\n",
    "                                        9: 'z'})\n",
    "            X['A8'] = X['A8'].replace({0: 'f', 1: 't'})\n",
    "            X['A9'] = X['A9'].replace({0: 'f', 1: 't'})\n",
    "            X['A11'] = X['A11'].replace({0: '0', 1: 't'})\n",
    "            X['A12'] = X['A12'].replace({1: 's', 2: 'g', 3: 'p'})\n",
    "            X = self.encode(X)\n",
    "            y = df[df.columns[-1]].to_frame('class')\n",
    "            \n",
    "        elif name == \"gastrointestinal\":\n",
    "            df = self.fetch_dataset(name)\n",
    "            X = df.iloc[:, 3:]\n",
    "            t1 = df.iloc[:, 0].to_frame('class')\n",
    "            t2 = df.iloc[:, 1].to_frame('class')\n",
    "            t3 = df.iloc[:, 2].to_frame('class')\n",
    "            indices_with_WL = t3[t3['class'] == '1'].index\n",
    "            indices_with_NBI = t3[t3['class'] == '2'].index\n",
    "            result_t2 = t2.loc[indices_with_WL]\n",
    "            X = X.loc[indices_with_WL]\n",
    "\n",
    "            y = self.multiclass_preprocessing(result_t2)\n",
    "            y = self.encode(y)\n",
    "            \n",
    "        elif name == \"votes\":\n",
    "\n",
    "            df = self.fetch_dataset(name)\n",
    "            X = df.iloc[:, 1:]\n",
    "            y = df.iloc[:, 0]\n",
    "            X = self.encode(X)\n",
    "            y = self.encode(y)\n",
    "\n",
    "        else:\n",
    "                    \n",
    "            df = self.fetch_dataset(name)\n",
    "            \n",
    "            X = df.data.features \n",
    "            y = df.data.targets \n",
    "            \n",
    "            df = pd.concat([X,y],axis=1)\n",
    "            df = df.sample(frac=1) # shuffle\n",
    "            \n",
    "            if name == 'careval':\n",
    "                X = self.encode(X)\n",
    "                y = self.multiclass_preprocessing(y)\n",
    "\n",
    "            y = self.encode(y)\n",
    "\n",
    "        return X, y\n",
    "        \n",
    "    def fetch_dataset(self, name):\n",
    "\n",
    "        prefix = 'data'+os.sep\n",
    "\n",
    "        if name == 'nursery':\n",
    "\n",
    "            file_path = prefix+name+os.sep+name+'.data'\n",
    "            df = pd.read_csv(file_path, header=None) \n",
    "            attr = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
    "            df.columns = attr\n",
    "\n",
    "        elif name == 'votes':\n",
    "\n",
    "            file_path = prefix+name+os.sep+'house-votes-84.data'\n",
    "            df = pd.read_csv(file_path, delimiter=',', header=None) \n",
    "            class_name = ['class']\n",
    "            features_name = [f'A{i+1}' for i in range(len(df.columns)-1)]\n",
    "            column_names = class_name+features_name\n",
    "            df.columns = column_names\n",
    "\n",
    "        elif name == 'australian':\n",
    "\n",
    "            file_path = prefix+name+os.sep+'australian.dat'\n",
    "            df = pd.read_csv(file_path, delimiter=' ', header=None) \n",
    "            attr = [f'A{i+1}' for i in range(15)]\n",
    "            df.columns = attr\n",
    "            \n",
    "        elif name == 'gastrointestinal':\n",
    "\n",
    "            file_path = prefix+name+os.sep+'data.txt'\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            list_of_rows = df.values.tolist()\n",
    "            raw_features = list_of_rows[3:]\n",
    "            labels_name = [f'label{i+1}' for i in range(3)]\n",
    "            features_name = [f'A{i+1}' for i in range(698)]\n",
    "            attr = labels_name + features_name\n",
    "            df = pd.DataFrame(list_of_rows).transpose()\n",
    "            df.columns = attr\n",
    "            \n",
    "        else:\n",
    "\n",
    "            df = fetch_ucirepo(id=self.files_id[name]) \n",
    "\n",
    "        return df\n",
    "    \n",
    "    def impute(self, df):\n",
    "        columns_with_missing_values = df.data.features.columns[df.data.features.isna().any()].tolist()\n",
    "\n",
    "        # imputation with mode\n",
    "        df.data.features.loc[:, columns_with_missing_values] = \\\n",
    "            df.data.features[columns_with_missing_values].fillna(df.data.features[columns_with_missing_values].mode().iloc[0])\n",
    "        return df\n",
    "    \n",
    "    def encode(self, df):\n",
    "        df = pd.get_dummies(df, drop_first=True)\n",
    "        df = df.astype(int)\n",
    "        return df\n",
    "    \n",
    "    def multiclass_preprocessing(self, y):\n",
    "        \n",
    "        majority_class = y['class'].mode().iloc[0]\n",
    "        y_copy = y.copy()\n",
    "        y_copy['binary_label'] = y_copy['class'].apply(lambda x: 1 if x == majority_class else 0)\n",
    "        y_copy = y_copy.drop('class', axis=1)\n",
    "        return y_copy\n",
    "    \n",
    "    def show_details(self, X, y):\n",
    "        nums_of_row = X.shape[0]\n",
    "        nums_of_feature = X.shape[1]\n",
    "        positive_count = y.sum()\n",
    "        print(f'nums_of_row:{nums_of_row}')\n",
    "        print(f'nums_of_feature:{nums_of_feature}')\n",
    "        if (positive_count.values < (nums_of_row - positive_count.values)):\n",
    "            positive_count == nums_of_row - positive_count.values\n",
    "        print(f'positive_count:{positive_count.values}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dh = DataHolder()\n",
    "    X, y = dh.get('gastrointestinal') # not yet 我通靈不到他怎麼算的\n",
    "#     X, y = dh.get('nursery') # done\n",
    "#     X, y = dh.get('australian') # done -> positive count 307 vs. 383\n",
    "#     X, y = dh.get('careval') # done \n",
    "#     X, y = dh.get('wisconsin') # done -> positive count 212 vs. 357\n",
    "#     X, y = dh.get('votes') # done -> positive count 168 vs. 267 \n",
    "    \n",
    "    # min max\n",
    "#     scaler = MinMaxScaler()\n",
    "    scaler = RobustScaler()\n",
    "    X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "    \n",
    "    dh.show_details(X,y)\n",
    "#     X = X.replace(0, -1)\n",
    "    y = y.replace(0, -1)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d74369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:500]\n",
    "y = y[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30a821",
   "metadata": {},
   "source": [
    "## P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63edf3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1(X:pd.DataFrame, y:np.ndarray, c:list = None, lambda_:list = [0.8, 0.8], M2:int = 100, M3:int = 100):\n",
    "    \"\"\" The cost-sensitive FS procedure \"\"\"\n",
    "    \"\"\" The first constraint causes infeasible \"\"\"\n",
    "    \"\"\" Model is feasible if zeta is continuous \"\"\"\n",
    "    \n",
    "    # set up\n",
    "    N = X.shape[1]\n",
    "    size = X.shape[0]   \n",
    "    x = np.array([X.iloc[i, :] for i in range(size)])\n",
    "    y = np.array(y).flatten()\n",
    "\n",
    "    if c == None:\n",
    "        c = [1 for _ in range(N)]\n",
    "\n",
    "    # create model\n",
    "    model = Model(\"P1\")\n",
    "    \n",
    "    # decision variables\n",
    "    w = [model.addVar(vtype=GRB.CONTINUOUS) for _ in range(N)]\n",
    "    beta = model.addVar(vtype=GRB.CONTINUOUS)\n",
    "    zeta = [model.addVar(lb=0, ub=1, vtype=GRB.BINARY) for _ in range(size)]\n",
    "    z = [model.addVar(vtype=GRB.BINARY) for _ in range(N)]\n",
    "    \n",
    "    \n",
    "    # constraints \n",
    "    model.addConstrs(\n",
    "        y[i] * (np.dot(np.array(w), x[i]) + beta) >= 1 - M2 * (1 - zeta[i]) for i in range(size)\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 - y[i]) for i in range(size)) >= lambda_[0] * quicksum(1 - y[i] for i in range(size))\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 + y[i]) for i in range(size)) >= lambda_[1] * quicksum(1 + y[i] for i in range(size))\n",
    "    )\n",
    "    model.addConstrs(\n",
    "        w[k] <= M3 * z[k] for k in range(N)\n",
    "    )\n",
    "    model.addConstrs(\n",
    "        w[k] >= -M3 * z[k] for k in range(N)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # objective function\n",
    "    model.setObjective(quicksum(c[k] * z[k] for k in range(N)), GRB.MINIMIZE)\n",
    "    \n",
    "    # optimization\n",
    "    model.optimize()\n",
    "    \n",
    "    # result\n",
    "    result = {\n",
    "        \"w\": [i.x for i in w],\n",
    "        \"beta\": beta.x,\n",
    "        \"z\": [i.x for i in z],\n",
    "        \"zeta\": [i.x for i in zeta]\n",
    "    }\n",
    "    \n",
    "    print(f'obj - {model.ObjVal}')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d7bae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-24\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1474 rows, 1473 columns and 37770 nonzeros\n",
      "Model fingerprint: 0x534656c3\n",
      "Variable types: 699 continuous, 774 integer (774 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-06, 1e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e+01, 1e+02]\n",
      "Presolve removed 935 rows and 472 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 539 rows, 1001 columns, 35897 nonzeros\n",
      "Variable types: 462 continuous, 539 integer (539 binary)\n",
      "Found heuristic solution: objective 27.0000000\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 593 iterations, 0.02 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   30   27.00000    0.00000   100%     -    0s\n",
      "H    0     0                      15.0000000    0.00000   100%     -    0s\n",
      "H    0     0                      11.0000000    0.82062  92.5%     -    0s\n",
      "     0     0    0.82062    0   72   11.00000    0.82062  92.5%     -    0s\n",
      "H    0     0                       5.0000000    0.82062  83.6%     -    0s\n",
      "     0     0    0.85587    0   75    5.00000    0.85587  82.9%     -    0s\n",
      "     0     0    0.92316    0   79    5.00000    0.92316  81.5%     -    0s\n",
      "     0     0    0.95937    0   75    5.00000    0.95937  80.8%     -    0s\n",
      "     0     0    0.96130    0   72    5.00000    0.96130  80.8%     -    0s\n",
      "     0     0    0.96296    0   78    5.00000    0.96296  80.7%     -    0s\n",
      "     0     0    0.96303    0   78    5.00000    0.96303  80.7%     -    0s\n",
      "     0     0    1.11534    0   47    5.00000    1.11534  77.7%     -    0s\n",
      "     0     0    1.20000    0   25    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20000    0   25    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20000    0   27    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20733    0   36    5.00000    1.20733  75.9%     -    0s\n",
      "     0     0    1.21696    0   39    5.00000    1.21696  75.7%     -    1s\n",
      "     0     0    1.21696    0   36    5.00000    1.21696  75.7%     -    1s\n",
      "     0     0    1.21696    0   36    5.00000    1.21696  75.7%     -    1s\n",
      "     0     0    1.22222    0   35    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   34    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   29    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   26    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   39    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   30    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   38    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   36    5.00000    1.22222  75.6%     -    1s\n",
      "     0     2    1.27778    0   24    5.00000    1.27778  74.4%     -    1s\n",
      "H   30    35                       2.0000000    1.27778  36.1%   215    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 6\n",
      "  MIR: 11\n",
      "  Flow cover: 49\n",
      "  Zero half: 1\n",
      "\n",
      "Explored 34 nodes (14177 simplex iterations) in 2.90 seconds (3.63 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 2 5 11 ... 27\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "obj - 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[131, 456]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = P1(X,y)[\"z\"]\n",
    "choose = [i for i in range(len(res)) if res[i] == 1]\n",
    "choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fdb041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1474 rows, 1473 columns and 37770 nonzeros\n",
      "Model fingerprint: 0x534656c3\n",
      "Variable types: 699 continuous, 774 integer (774 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-06, 1e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e+01, 1e+02]\n",
      "Presolve removed 935 rows and 472 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 539 rows, 1001 columns, 35897 nonzeros\n",
      "Variable types: 462 continuous, 539 integer (539 binary)\n",
      "Found heuristic solution: objective 27.0000000\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 593 iterations, 0.02 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   30   27.00000    0.00000   100%     -    0s\n",
      "H    0     0                      15.0000000    0.00000   100%     -    0s\n",
      "H    0     0                      11.0000000    0.82062  92.5%     -    0s\n",
      "     0     0    0.82062    0   72   11.00000    0.82062  92.5%     -    0s\n",
      "H    0     0                       5.0000000    0.82062  83.6%     -    0s\n",
      "     0     0    0.85587    0   75    5.00000    0.85587  82.9%     -    0s\n",
      "     0     0    0.92316    0   79    5.00000    0.92316  81.5%     -    0s\n",
      "     0     0    0.95937    0   75    5.00000    0.95937  80.8%     -    0s\n",
      "     0     0    0.96130    0   72    5.00000    0.96130  80.8%     -    0s\n",
      "     0     0    0.96296    0   78    5.00000    0.96296  80.7%     -    0s\n",
      "     0     0    0.96303    0   78    5.00000    0.96303  80.7%     -    0s\n",
      "     0     0    1.11534    0   47    5.00000    1.11534  77.7%     -    0s\n",
      "     0     0    1.20000    0   25    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20000    0   25    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20000    0   27    5.00000    1.20000  76.0%     -    0s\n",
      "     0     0    1.20733    0   36    5.00000    1.20733  75.9%     -    0s\n",
      "     0     0    1.21696    0   39    5.00000    1.21696  75.7%     -    0s\n",
      "     0     0    1.21696    0   36    5.00000    1.21696  75.7%     -    0s\n",
      "     0     0    1.21696    0   36    5.00000    1.21696  75.7%     -    1s\n",
      "     0     0    1.22222    0   35    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   34    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   29    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   26    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   39    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   30    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   38    5.00000    1.22222  75.6%     -    1s\n",
      "     0     0    1.22222    0   36    5.00000    1.22222  75.6%     -    1s\n",
      "     0     2    1.27778    0   24    5.00000    1.27778  74.4%     -    2s\n",
      "H   30    35                       2.0000000    1.27778  36.1%   215    3s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 6\n",
      "  MIR: 11\n",
      "  Flow cover: 49\n",
      "  Zero half: 1\n",
      "\n",
      "Explored 34 nodes (14177 simplex iterations) in 3.13 seconds (3.63 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 2 5 11 ... 27\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "obj - 2.0\n"
     ]
    }
   ],
   "source": [
    "result = P1(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf35e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 76)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"zeta\"].count(1), len(result[\"zeta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a5a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34563197665023776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"beta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1f4b7",
   "metadata": {},
   "source": [
    "### 其實 P2, P3 可以只寫成一個，但我不確定會不會比較好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a11151",
   "metadata": {},
   "source": [
    "## P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0a66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(X:pd.DataFrame, y, zk:list=None, C:int=100, lambda_:list=[0.5,0.5], M1:int=100):\n",
    "    \"\"\" Cost-sensitive sparse SVMs - linear \"\"\"\n",
    "    # set up\n",
    "    N = X.shape[1]\n",
    "    size = X.shape[0]   \n",
    "    x = np.array([X.iloc[i, :] for i in range(size)])\n",
    "    y = np.array(y).flatten()\n",
    "    \n",
    "    \n",
    "    \n",
    "    z = [0 for _ in range(N)]\n",
    "    for i in zk:\n",
    "        z[i] = 1\n",
    "        \n",
    "    # create model \n",
    "    model = Model(\"P2\")\n",
    "    \n",
    "    # decision variables\n",
    "    w = [model.addVar(vtype=GRB.CONTINUOUS) for _ in range(N)]\n",
    "    beta = model.addVar(vtype=GRB.CONTINUOUS)\n",
    "    xi = [model.addVar(lb=0,vtype=GRB.CONTINUOUS) for _ in range(size)]\n",
    "    zeta = [model.addVar(vtype=GRB.BINARY) for _ in range(size)]\n",
    "    \n",
    "    # constraints\n",
    "    model.addConstrs(\n",
    "        y[i] * (quicksum(w[j] * z[j] * x[i][j] for j in range(N)) + beta) >= 1 - xi[i] for i in range(size)\n",
    "    )\n",
    "    model.addConstrs(\n",
    "        xi[i] <= M1 * (1 - zeta[i]) for i in range(size)\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 - y[i]) for i in range(size)) >= lambda_[0] * quicksum(1 - y[i] for i in range(size))\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 + y[i]) for i in range(size)) >= lambda_[1] * quicksum(1 + y[i] for i in range(size))\n",
    "    )\n",
    "    \n",
    "    # objective function\n",
    "    model.setObjective(quicksum(w[j] ** 2 * z[j] for j in range(N)) + C * quicksum(xi[i] for i in range(size)), GRB.MINIMIZE)\n",
    "    \n",
    "    # optimization\n",
    "    model.optimize()\n",
    "    \n",
    "    \n",
    "    # result\n",
    "    result = {\n",
    "        \"w\": [i.x for i in w],\n",
    "        \"beta\": beta.x,\n",
    "        \"xi\": [i.x for i in xi]\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55f808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09722893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 154 rows, 851 columns and 532 nonzeros\n",
      "Model fingerprint: 0xc5f8aca2\n",
      "Model has 2 quadratic objective terms\n",
      "Variable types: 775 continuous, 76 integer (76 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 1e+02]\n",
      "  Objective range  [1e+02, 1e+02]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Found heuristic solution: objective 14815.994522\n",
      "Presolve removed 2 rows and 700 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 152 rows, 151 columns, 571 nonzeros\n",
      "Presolved model has 2 quadratic objective terms\n",
      "Variable types: 77 continuous, 74 integer (74 binary)\n",
      "\n",
      "Root relaxation: objective 4.618659e+03, 439 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 4618.65916    0   22 14815.9945 4618.65916  68.8%     -    0s\n",
      "H    0     0                    10433.757728 4618.65916  55.7%     -    0s\n",
      "H    0     0                    8954.0321888 4618.65916  48.4%     -    0s\n",
      "     0     0 4618.65916    0   22 8954.03219 4618.65916  48.4%     -    0s\n",
      "H    0     0                    5378.0201055 4618.65916  14.1%     -    0s\n",
      "     0     0 4618.65916    0   13 5378.02011 4618.65916  14.1%     -    0s\n",
      "     0     0 4631.52055    0   20 5378.02011 4631.52055  13.9%     -    0s\n",
      "     0     0 4632.87494    0   21 5378.02011 4632.87494  13.9%     -    0s\n",
      "     0     0 4632.91585    0   21 5378.02011 4632.91585  13.9%     -    0s\n",
      "     0     0 4634.62379    0   21 5378.02011 4634.62379  13.8%     -    0s\n",
      "H    0     0                    4885.1188163 4634.62379  5.13%     -    0s\n",
      "     0     0 4662.23203    0   24 4885.11882 4662.23203  4.56%     -    0s\n",
      "     0     0 4667.59256    0   25 4885.11882 4667.59256  4.45%     -    0s\n",
      "     0     0 4667.59256    0   26 4885.11882 4667.59256  4.45%     -    0s\n",
      "     0     0 4734.74926    0   26 4885.11882 4734.74926  3.08%     -    0s\n",
      "H    0     0                    4783.2624368 4734.74926  1.01%     -    0s\n",
      "     0     1 4734.74926    0   21 4783.26244 4734.74926  1.01%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 17\n",
      "  Implied bound: 6\n",
      "  Clique: 1\n",
      "  MIR: 17\n",
      "  Relax-and-lift: 9\n",
      "\n",
      "Explored 202 nodes (2381 simplex iterations) in 0.10 seconds (0.04 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 4783.26 4885.12 5378.02 ... 14816\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.783262436751e+03, best bound 4.783262436751e+03, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "res = P2(X,y, choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c89e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.9682362709774368,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.2186710873515274,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"w\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdc351",
   "metadata": {},
   "source": [
    "## P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9da087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_(z:list):\n",
    "    N = len(z)\n",
    "    def func(x,x_prime, gamma=0.5):\n",
    "        \"\"\" gamma need to be tuned \"\"\"\n",
    "#         global gamma\n",
    "        return np.exp(-gamma * sum(z[k] * (x[k] - x_prime[k]) ** 2 for k in range(N)))\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3bbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P3(X:pd.DataFrame, y, zk:list=None, C:int=5, lambda_:list=[0.1, 0.1], M1:int=100):\n",
    "    # set up\n",
    "    N = X.shape[1]\n",
    "    size = X.shape[0]   \n",
    "    x = np.array([X.iloc[i, :] for i in range(size)])\n",
    "    y = np.array(y).flatten()\n",
    "\n",
    "    z = [0 for _ in range(N)]\n",
    "    for i in zk:\n",
    "        z[i] = 1\n",
    "    \n",
    "    global K_\n",
    "    K = K_(z)\n",
    "    \n",
    "    # create model\n",
    "    model = Model(\"P3\")\n",
    "    \n",
    "    # decision variables\n",
    "    alpha = [model.addVar(lb=0, ub=C/2, vtype=GRB.CONTINUOUS) for _ in range(size)]\n",
    "    xi = [model.addVar(lb=0, vtype=GRB.CONTINUOUS) for _ in range(size)]\n",
    "    zeta = [model.addVar(vtype=GRB.BINARY) for _ in range(size)]\n",
    "    beta = model.addVar(vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    # constraints\n",
    "    model.addConstrs(\n",
    "        (y[i] * (quicksum(alpha[j] * y[j] * K(x[i], x[j]) for j in range(size)) + beta) >= 1 - xi[i]) for i in range(size)\n",
    "    )\n",
    "    model.addConstrs(\n",
    "        (xi[i] <= M1 * (1 - zeta[i])) for i in range(size)\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(alpha[i] * y[i] for i in range(size)) == 0\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 - y[i]) for i in range(size)) >= lambda_[0] * (quicksum(1 - y[i] for i in range(size)))\n",
    "    )\n",
    "    model.addConstr(\n",
    "        quicksum(zeta[i] * (1 + y[i]) for i in range(size)) >= lambda_[1] * (quicksum(1 + y[i] for i in range(size)))\n",
    "    )\n",
    "    \n",
    "    # optimization\n",
    "    model.optimize()\n",
    "    \n",
    "    # result\n",
    "    result = {\n",
    "        \"alpha\": [i.x for i in alpha],\n",
    "        \"xi\": [i.x for i in xi],\n",
    "        \"zeta\": [i.x for i in zeta],\n",
    "        \"beta\": beta.x\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7912e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 155 rows, 229 columns and 6232 nonzeros\n",
      "Model fingerprint: 0x0d61cf84\n",
      "Variable types: 153 continuous, 76 integer (76 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-05, 1e+02]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+00, 2e+00]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': [2.0679267526673035,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3441549774849408,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.3544988060940259,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.4224255587613293,\n",
       "  0.0,\n",
       "  0.3441549774849408,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'xi': [1.3184866576672936,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.091214429822691,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.11074469474771681,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.45091847882158087,\n",
       "  0.8600823835016674,\n",
       "  1.9856777406975115,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.888671015426413,\n",
       "  0.0,\n",
       "  0.3514259558864874,\n",
       "  0.0,\n",
       "  0.9571813757291635,\n",
       "  0.0,\n",
       "  2.4057885703112336,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6546484292451522,\n",
       "  0.0,\n",
       "  3.7516501018449437,\n",
       "  0.0,\n",
       "  0.5254646145903772,\n",
       "  0.0,\n",
       "  0.678361313839215,\n",
       "  1.302133805169299,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.842479872670153,\n",
       "  3.0221017630442466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.876583536286279,\n",
       "  3.8406064877173254,\n",
       "  0.0,\n",
       "  1.577475542041201,\n",
       "  0.5262656836789894,\n",
       "  5.215780490925747,\n",
       "  0.002820185888278207,\n",
       "  2.458015207828817,\n",
       "  1.237182070118032,\n",
       "  0.0,\n",
       "  1.8497442386016183,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6646331497703084,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.474287906294976,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.394401150533011,\n",
       "  0.09145222124663417,\n",
       "  2.3496242009846022,\n",
       "  0.6248901708213219,\n",
       "  3.8542823431868607,\n",
       "  0.0,\n",
       "  1.4309104975666518,\n",
       "  0.0,\n",
       "  2.0489538916717898,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.806593083390247],\n",
       " 'zeta': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'beta': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3(X, y, choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c98496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51193696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
